# -*- coding: utf-8 -*-
"""Brain_tumer_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZRhJnsXa-oE3BOPOREkiLjJ_7NTXnuij
"""

# Replace with your folder name
dataset_path = '/content/drive/MyDrive/brain_tumer_ml/Dataset'
train_dir = dataset_path + '/Train'
test_dir = dataset_path + '/Test'

import tensorflow as tf

from google.colab import drive
drive.mount('/content/drive')

img_height = 64
img_width = 64

train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    labels='inferred',
    label_mode='int',
    color_mode='grayscale',
    batch_size=32,
    image_size=(img_height, img_width),
    shuffle=True,
    seed=123
)

test_ds = tf.keras.utils.image_dataset_from_directory(
    test_dir,
    labels='inferred',
    label_mode='int',
    color_mode='grayscale',
    batch_size=32,
    image_size=(img_height, img_width),
    shuffle=False
)


class_names = train_ds.class_names
print("Classes:", class_names)


normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))

print("Classes:", class_names)
print("Number of classes:", len(class_names))

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(64, 64, 1)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary output
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

import matplotlib.pyplot as plt
import random

unbatched_ds = train_ds.unbatch()

all_images = list(unbatched_ds)
sampled = random.sample(all_images, 8)
plt.figure(figsize=(12, 8))

for i, (image, label) in enumerate(sampled):
    plt.subplot(2, 4, i + 1)
    plt.imshow(image.numpy().squeeze(), cmap='gray')
    plt.title(class_names[int(label.numpy())])
    plt.axis('off')

plt.tight_layout()
plt.show()

test_ds

history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=20
)

import numpy as np

predicted_labels = []
true_labels = []


for images, labels in test_ds:

    preds = model.predict(images)

    preds = (preds > 0.5).astype(int).flatten()


    predicted_labels.extend(preds)
    true_labels.extend(labels.numpy())

predicted_labels = np.array(predicted_labels)
true_labels = np.array(true_labels)


accuracy = np.mean(true_labels == predicted_labels)
print(f"Manual Accuracy: {accuracy:.4f}")

loss, eval_acc = model.evaluate(test_ds)
print(f"Model Evaluate Accuracy: {eval_acc:.4f}")

img_path = '/content/drive/MyDrive/brain_tumer_ml/Dataset/Test/no/14 no.jpg'

img = tf.keras.utils.load_img(
    img_path, color_mode='grayscale', target_size=(64, 64)
)


img_array = tf.keras.utils.img_to_array(img)


img_array = img_array / 255.0


img_array = tf.expand_dims(img_array, axis=0)

# Predict
prediction = model.predict(img_array)

if prediction[0][0] > 0.5:
    print("Prediction: YES")
else:
    print("Prediction: NO")

model.save('my_model.h5')

loss, eval_acc = model.evaluate(test_ds)

